{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job_PCA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zElijvIVirvA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "#import cv2 as cv\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob as gb\n",
        "path=\"/content/drive/MyDrive/Task3/Train\"\n",
        "main_folder = os.listdir(path)\n",
        "#picture = os.listdir(main_folder)\n",
        "img_list = []\n",
        "binary_list = []\n",
        "folder_belonging = []\n",
        "folder_label=[]\n",
        "for n in range(0,len(main_folder)):\n",
        "  if main_folder[n]==\".ipynb_checkpoints\":\n",
        "    #print(main_folder[i])\n",
        "    continue\n",
        "  pics = path + \"/\" + main_folder[n]\n",
        "  for m in os.listdir(pics):\n",
        "    x = pics + \"/\" + m\n",
        "    imagess = cv2.imread(x)\n",
        "    img_list.append(imagess)\n",
        "    folder_belonging.append(pics)\n",
        "    print(pics)\n",
        "    folder_label.append(main_folder[n])\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "#print(path)\n",
        "#print(folder_label)\n",
        "#print(img_list)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img = cv2.imread('/content/drive/MyDrive/Task3/Train/Do Not Enter/Charlotte__0000006229_CROP_1.jpg')\n",
        "\n",
        "pca_10 = PCA(n_components=10)\n",
        "for n in range(0,len(img_list)):\n",
        "  imgGray = color.rgb2gray(img_list[n])\n",
        "  #cv2_imshow(imgGray)\n",
        "\n",
        "  img_pca_10_reduced = pca_10.fit_transform(imgGray)\n",
        "  img_pca_10_recovered = pca_10.inverse_transform(img_pca_10_reduced)\n",
        "\n",
        "  #Below Error Mohtishim\n",
        "  image_pca_10 = img_pca_10_recovered.reshape((-1,1,230,219))\n",
        "  cv2_imshow(image_pca_10, cmap='gray_r')\n",
        "  plt.grid()\n",
        "#For Variability IN PCA\n",
        "  plt.plot(np.cumsum(pca_10.explained_variance_ratio_ * 100))\n",
        "  plt.xlabel('Number of components')\n",
        "  plt.ylabel('Explained variance')\n",
        "  plt.savefig('Scree plot.png')\n",
        "  plt.title('Compressed image with  10 components', fontsize=15, pad=15)\n",
        "  plt.savefig(\"image_pca_10.png\")\n",
        "#second_image = cv2.resize(img,(200,200),3)\n",
        "#second_image = cv2.resize(img,(230,219))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Wx3xlaenXvXE",
        "outputId": "fbc346fc-fa24-4b1d-881b-9e23b83bc81e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7d763714d457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mimg_pca_10_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mimg_pca_10_recovered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pca_10_reduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mimage_pca_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_pca_10_recovered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m230\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m219\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pca_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4002 into shape (1,230,219)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WbYyBU-0o880"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}